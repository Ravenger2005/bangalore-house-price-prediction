ğŸ  Bangalore House Price Prediction
Description

End-to-end Machine Learning project to predict Bangalore house prices.

.Built a regression model from scratch using Python, Pandas, NumPy, and Scikit-learn.

.Performed data cleaning, feature engineering, dimensionality reduction, model selection, and cross-validation.

.Exposed the trained model through a Flask API and a minimal browser-based UI for interactive prediction.

.Deployed on Render for public access.



ğŸ“Œ Project Overview

This project converts raw real-estate data into a production-ready prediction system.

Includes:

âœ” Data cleaning
âœ” Feature engineering
âœ” Dimensionality reduction
âœ” Model selection & cross validation
âœ” Model export (pickle)
âœ” Flask REST API
âœ” UI in browser
âœ” Deployment on Render




ğŸ§± System Architecture

               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   Raw Dataset   â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Data Cleaning   â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Feature Engg.   â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Model Training  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Pickle + Columns.json â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Flask API       â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Browser UI      â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



ğŸ“‚ Project Structure

.
â”œâ”€â”€ data/                      # raw dataset
â”œâ”€â”€ model/                     # model.pkl + columns.json
â”œâ”€â”€ server/                    # Flask backend
â”œâ”€â”€ client/                    # UI frontend
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Procfile
â””â”€â”€ README.md




ğŸ§© Project Workflow (End-to-End)

The complete development pipeline of this project follows a real-world machine learning lifecycle:

1. Data Acquisition

.Dataset loaded from Kaggle / CSV

.Initial inspection of column types & data distribution

2. Exploratory Data Analysis (EDA)

.Performed to understand relationships & detect patterns:

.Distribution plots (histograms, countplots)

.Correlation heatmap

.Outlier visualization

.Null value analysis

3. Data Cleaning

.Core cleaning tasks included:

.Handling missing values (mean/median/most-freq strategies)

.Removing outliers using IQR / domain logic

.Removing duplicates

.Feature normalization & scaling

4. Feature Engineering

.New features were created to improve model accuracy:

.Domain-based derived features

.Encoding categorical variables

.Normalization for numerical variables

.Train-test splitting for supervised learning

5. Dimensionality Reduction

.To reduce feature complexity and improve training efficiency:

.PCA (Principal Component Analysis) applied

.Components selected based on explained variance threshold

.Reduced computational cost without losing key information

6. Model Selection

.Multiple algorithms were benchmarked:

.Linear Regression

.Decision Tree

.Lasso Regression

7. Model Evaluation & Cross-Validation

.Used proper evaluation techniques:

.K-Fold Cross Validation

.Classification metrics (Accuracy, Precision, Recall, F1, AUC)

.Comparisons tabulated to identify best performer

8. Final Model Training

.The best model was retrained on full training set:

.Hyperparameter tuning performed (GridSearch / RandomizedSearch)

.Final performance validated on unseen test data

.Linear Regression was chosen for providing high accuracy.

9. Model Serialization

.Once finalized, model was exported for deployment using: pickle

10. Backend (Flask Web App)

ğŸŒ Flask API Endpoints

| Endpoint              | Method | Description                    |
| --------------------- | ------ | ------------------------------ |
| `/get_location_names` | GET    | Returns list of location names |
| `/predict_home_price` | POST   | Predicts house price           |


POST Body Example:

{
  "total_sqft": 1200,
  "bhk": 3,
  "bath": 3,
  "location": "Whitefield"
}

response:

{
  "estimated_price": 84.5
}


ğŸ¨ Frontend UI

Built using:

HTML

CSS

JavaScript

User inputs â†’ AJAX request â†’ shows estimated price.

ğŸš€ Deployment Ready

Configured with:

âœ” requirements.txt
âœ” Procfile for Gunicorn
âœ” virtual env support
âœ” Flask entrypoint updated to production mode

Supports deployment on:

->Render



ğŸ§¾ Tech Stack

| Category        | Tools                       |
| --------------- | --------------------------- |
| Language        | Python                      |
| ML              | Pandas, NumPy, Scikit-Learn |
| Backend         | Flask                       |
| Serving         | Gunicorn                    |
| Deployment      | Render                      |
| Version Control | Git + GitHub                |


ğŸ¯ Highlights

âœ” Complete ML workflow
âœ” Real-world dataset
âœ” Advanced outlier removal
âœ” Cross validated model
âœ” API + UI for real usage
âœ” Deployment ready build


ğŸ“ Conclusion

This project demonstrates converting raw data into a production-grade predictive system combining:

Data Science + ML Engineering + Software + Deployment.
